{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning for CV - Project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install torch https://pytorch.org/get-started/locally/\n",
    "\n",
    "%pip install numpy kagglehub matplotlib opencv-python --quiet\n",
    "%pip install segmentation-models-pytorch --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Import libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch import utils\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "\n",
    "from torch.utils.data import Dataset as BaseDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation of Underwater Imagery\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/ashish2001/semantic-segmentation-of-underwater-imagery-suim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"ashish2001/semantic-segmentation-of-underwater-imagery-suim\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping categories in TEST/masks\n",
    "category_colors = {\n",
    "    \"Saliency\": [0, 0, 0],  # Background (waterbody) (Called also BW)\n",
    "    \"HD\": [0, 0, 255],      # Human divers\n",
    "    \"PF\": [0, 255, 0],      # Aquatic plants and sea-grass\n",
    "    \"WR\": [0, 255, 255],    # Wrecks and ruins\n",
    "    \"RO\": [255, 0, 0],      # Robots (AUVs/ROVs/instruments)\n",
    "    \"RI\": [255, 0, 255],    # Reefs and invertebrates\n",
    "    \"FV\": [255, 255, 0],    # Fish and vertebrates\n",
    "    \"SR\": [255, 255, 255],  # Sea-floor and rocks\n",
    "}\n",
    "\n",
    "CLASSES = list(category_colors.keys())\n",
    "color_to_class = {tuple(value): idx for idx, (_, value) in enumerate(category_colors.items())}\n",
    "idx_to_class = {idx: class_name for idx, class_name in enumerate(CLASSES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rgb_to_class(mask, color_to_class):\n",
    "    h, w, _ = mask.shape\n",
    "    class_mask = np.zeros((h, w), dtype=np.int64)\n",
    "    \n",
    "    for color, class_idx in color_to_class.items():\n",
    "        color = np.array(color, dtype=np.uint8)\n",
    "        matches = np.all(mask == color, axis=-1)  # Find pixels matching this color\n",
    "        class_mask[matches] = class_idx\n",
    "    \n",
    "    return class_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(BaseDataset):\n",
    "    def __init__(self, base_path, train=True, augmentation=None, preprocessing=None):        \n",
    "        self.base_path = base_path\n",
    "        self.train = train\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "        if train:\n",
    "            # Training/validation data\n",
    "            self.images_dir = os.path.join(base_path, \"train_val\", \"images\")\n",
    "            self.masks_dir = os.path.join(base_path, \"train_val\", \"masks\")\n",
    "        else:\n",
    "            # Test data\n",
    "            self.images_dir = os.path.join(base_path, \"TEST\", \"images\")\n",
    "            self.masks_dir = os.path.join(base_path, \"TEST\", \"masks\")\n",
    "        \n",
    "        self.image_files = os.listdir(self.images_dir)\n",
    "        self.class_values = [key for key,_ in enumerate(CLASSES)]\n",
    "\n",
    "        # Get all the mask files from the main masks folder and its subdirectories (for test set)\n",
    "        if train:\n",
    "            self.mask_files = os.listdir(self.masks_dir)\n",
    "            self.subfolders = None\n",
    "        else:\n",
    "            self.mask_files = [\n",
    "                filename for filename in os.listdir(self.masks_dir)\n",
    "                if os.path.isfile(os.path.join(self.masks_dir, filename))\n",
    "            ]\n",
    "            self.subfolders = [\n",
    "                filename for filename in os.listdir(self.masks_dir)\n",
    "                if os.path.isdir(os.path.join(self.masks_dir, filename))\n",
    "            ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image with cv2\n",
    "        img_path = os.path.join(self.images_dir, self.image_files[idx])\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "\n",
    "        mask_name = self.image_files[idx].split(\".\")[0]+\".bmp\"\n",
    "\n",
    "        # Prepare mask\n",
    "        mask_path = os.path.join(self.masks_dir, mask_name)\n",
    "        rgb_mask = cv2.imread(mask_path, cv2.IMREAD_COLOR)\n",
    "        rgb_mask = cv2.cvtColor(rgb_mask, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        \n",
    "        # Convert RGB mask to class index mask\n",
    "        mask = convert_rgb_to_class(rgb_mask, color_to_class)\n",
    "        masks = [(mask == v) for v in self.class_values]\n",
    "        mask = np.stack(masks, axis=-1).astype('float')\n",
    "        \n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "                       \n",
    "        return image, mask\n",
    "    \n",
    "    def get_mask_by_class(self, item_idx, class_name):\n",
    "        if self.train == True:\n",
    "            return None\n",
    "        else:\n",
    "            if isinstance(class_name, int):\n",
    "                class_name = idx_to_class[class_name]\n",
    "            mask_name = self.image_files[item_idx].split(\".\")[0]+\".bmp\"\n",
    "            mask_path = os.path.join(self.masks_dir, class_name, mask_name)\n",
    "            rgb_mask = cv2.imread(mask_path, cv2.IMREAD_COLOR)\n",
    "            rgb_mask = cv2.cvtColor(rgb_mask, cv2.COLOR_BGR2RGB) \n",
    "            return rgb_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(image, mask, alpha=0.5, save=None):\n",
    "    # Normalize the image if necessary\n",
    "    if image.max() > 1:\n",
    "        image = image / 255.0\n",
    "\n",
    "    # Determine if the mask is multi-class or RGB\n",
    "    if mask.ndim == 3 and mask.shape[-1] > 3:  # Multi-class segmentation\n",
    "        # Define a color map with unique colors for each class\n",
    "        colors = plt.get_cmap('tab20', mask.shape[2])\n",
    "        cmap = ListedColormap([colors(i) for i in range(mask.shape[2])])\n",
    "\n",
    "        # Get the class with the highest score at each pixel\n",
    "        combined_mask = np.argmax(mask, axis=2)\n",
    "\n",
    "        # Create a color image of the mask for overlay\n",
    "        color_mask = cmap(combined_mask / combined_mask.max())[:, :, :3]  # Remove alpha channel if present\n",
    "    elif mask.ndim == 3 and mask.shape[-1] == 3:  # RGB image mask\n",
    "        # Normalize RGB mask if necessary\n",
    "        if mask.max() > 1:\n",
    "            mask = mask / 255.0\n",
    "        color_mask = mask\n",
    "    else:\n",
    "        raise ValueError(\"Mask must have shape (H, W, num_classes) or (H, W, 3).\")\n",
    "\n",
    "    # Ensure the image has the shape (height, width, channels)\n",
    "    if image.shape[0] == 3:  # If shape is (3, height, width)\n",
    "        image = np.transpose(image, (1, 2, 0))  # Transpose to (height, width, 3)\n",
    "\n",
    "    # Overlay the mask on the original image\n",
    "    overlayed_image = (1 - alpha) * image + alpha * color_mask\n",
    "\n",
    "    # Clip values to ensure they stay within [0, 1]\n",
    "    overlayed_image = np.clip(overlayed_image, 0, 1)\n",
    "\n",
    "    # Plot original and overlayed images side by side\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Show the original image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Show the image with segmentation overlay\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(overlayed_image)\n",
    "    plt.title(\"Image with Segmentation Overlay\")\n",
    "    plt.axis('off')\n",
    "    if save is not None:\n",
    "        plt.savefig(f\"{save}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_if_not_exist(folder):\n",
    "  if not os.path.exists(folder):\n",
    "      os.makedirs(folder)\n",
    "      \n",
    "def write_csv(filename, headers, values, multi_rows=False):\n",
    "  with open(f\"{filename}.csv\", mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)\n",
    "        if multi_rows == True:\n",
    "          for v in values:\n",
    "            writer.writerow(v)\n",
    "        else:\n",
    "          writer.writerow(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pad(image, multiple=32):\n",
    "  h, w = image.shape[:2]\n",
    "  return h % multiple==0 and w % multiple==0\n",
    "\n",
    "def pad_to_multiple(image, multiple=32):\n",
    "    \"\"\"\n",
    "    Pad an image so that its height and width are divisible by a given multiple.\n",
    "    Args:\n",
    "        image: Input image as a numpy array.\n",
    "        multiple: The number to which height and width should be divisible.\n",
    "\n",
    "    Returns:\n",
    "        Padded image.\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # Calculate the necessary padding\n",
    "    new_h = ((h + multiple - 1) // multiple) * multiple\n",
    "    new_w = ((w + multiple - 1) // multiple) * multiple\n",
    "    \n",
    "    pad_h = new_h - h\n",
    "    pad_w = new_w - w\n",
    "    \n",
    "    # Pad the image (adding padding evenly to top, bottom, left, right)\n",
    "    padded_image = cv2.copyMakeBorder(\n",
    "        image,\n",
    "        0, pad_h,   # Top and bottom padding\n",
    "        0, pad_w,   # Left and right padding\n",
    "        cv2.BORDER_CONSTANT,\n",
    "        value=[0, 0, 0]  # Black padding\n",
    "    )\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Unet-resnet50\"\n",
    "EPOCHS = 100\n",
    "MODEL_FOLDER = f\"./results/{MODEL_NAME}\"\n",
    "INDEX_RUN = 2\n",
    "  \n",
    "RESULTS_FOLDER = f\"{MODEL_FOLDER}/{INDEX_RUN}-epochs{EPOCHS}\"\n",
    "\n",
    "MASKS_FOLDER = f\"{RESULTS_FOLDER}/masks\"\n",
    "TEST_FOLDER = f\"{RESULTS_FOLDER}/test\"\n",
    "create_folder_if_not_exist(TEST_FOLDER)\n",
    "\n",
    "BEST_MODEL = f'{RESULTS_FOLDER}/best_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'resnet18'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "ACTIVATION = 'softmax2d'  # Use sigmoid  if doing one-single-class segmentation\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class UNetWithDropout(smp.Unet):\n",
    "    def __init__(self, encoder_name, encoder_weights, classes, activation, in_channels=3, dropout_prob=0.5):\n",
    "        super().__init__(\n",
    "            encoder_name=encoder_name,\n",
    "            encoder_weights=encoder_weights,\n",
    "            classes=classes,\n",
    "            activation=activation,\n",
    "            in_channels=in_channels\n",
    "        )\n",
    "        self.dropout = nn.Dropout2d(p=dropout_prob)  # Dropout layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward method with dropout added to the encoder and decoder outputs.\"\"\"\n",
    "        features = self.encoder(x)\n",
    "        features = [self.dropout(feature) for feature in features]  # Apply dropout after each encoder layer\n",
    "        decoder_output = self.decoder(*features)  # Decode features\n",
    "        masks = self.segmentation_head(decoder_output)  # Generate segmentation mask\n",
    "        return masks\n",
    "\n",
    "# Create FPN model with pretrained encoder\n",
    "model = UNetWithDropout(\n",
    "    encoder_name=ENCODER,\n",
    "    encoder_weights=ENCODER_WEIGHTS,  # Use 'imagenet' pretrained weights for encoder initialization\n",
    "    classes=len(CLASSES),  # Number of classes in your dataset\n",
    "    activation=ACTIVATION,  # Activation function for the output\n",
    "    in_channels=3,  # Model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    dropout_prob=0.3\n",
    "    # decoder_dropout=0.5\n",
    ")\n",
    "\n",
    "# Get preprocessing function for the encoder\n",
    "preprocessing_fn = get_preprocessing_fn(ENCODER, pretrained=ENCODER_WEIGHTS)\n",
    "\n",
    "print(\"Running on: \", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class pixel counts from your data\n",
    "pixel_counts = torch.tensor([189688979, 12313599, 11940788, 37353994, 2917692, 186100654, 39309599, 78415339])\n",
    "\n",
    "# Compute weights inversely proportional to pixel counts\n",
    "total_pixels = pixel_counts.sum()\n",
    "class_weights = total_pixels / (pixel_counts * len(pixel_counts))\n",
    "class_weights += class_weights.mean()\n",
    "class_weights = class_weights / class_weights.max()  # Normalize weights to the range [0, 1]\n",
    "print(\"Normalized Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedDiceLoss(nn.Module):\n",
    "    def __init__(self, class_weights):\n",
    "        super(WeightedDiceLoss, self).__init__()\n",
    "        self.class_weights = class_weights\n",
    "        self.__name__ = \"dice_loss\"  # Add this line\n",
    "        \n",
    "    def forward(self, outputs, targets):\n",
    "        dice_loss = 0.0\n",
    "        for class_idx, weight in enumerate(self.class_weights):\n",
    "            # Check if the class is present in either targets or outputs\n",
    "            if targets[:, class_idx].sum() > 0 or outputs[:, class_idx].sum() > 0:\n",
    "                # Calculate Dice for this class\n",
    "                intersection = (outputs[:, class_idx] * targets[:, class_idx]).sum()\n",
    "                union = outputs[:, class_idx].sum() + targets[:, class_idx].sum()\n",
    "                dice = (2.0 * intersection) / (union + 1e-5)\n",
    "\n",
    "                # Apply the weight to the loss for this class\n",
    "                dice_loss += weight * (1 - dice)\n",
    "\n",
    "        return dice_loss / len(self.class_weights)\n",
    "\n",
    "class_weights = class_weights.to(DEVICE)  # Move to the correct device\n",
    "\n",
    "weighted_loss = WeightedDiceLoss(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = weighted_loss #utils.losses.DiceLoss() \n",
    "metrics = [\n",
    "    utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    dict(params=model.parameters(), lr=0.0001, weight_decay=1e-4),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load(BEST_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Let's some outputs of the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(base_path=path, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_headers = [\"Pixel predicted\", \"Pixel true\", \"Pixel intersetion\", \"Pixel union\"]\n",
    "headers = [\"Image\"] + [f\"{value} {idx}\" for value in base_headers for idx in idx_to_class]\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_colors = {v: k for k, v in color_to_class.items()}\n",
    "\n",
    "def create_color_mask(pred_mask, class_colors):\n",
    "    # Initialize the colored mask with black (default background)\n",
    "    height, width = pred_mask.shape\n",
    "    colored_mask = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    \n",
    "    masks_per_class = []\n",
    "\n",
    "    # Loop through each class and apply the corresponding color\n",
    "    for class_id, color in class_colors.items():\n",
    "        class_mask = (pred_mask == class_id)  # Create a binary mask for the class\n",
    "        colored_mask[class_mask] = color      # Apply the color where the class mask is 1\n",
    "        \n",
    "        mask_per_class = np.full((height, width, 3), fill_value=(200, 200, 200), dtype=np.uint8) # Set a light grey color to see also the black mask\n",
    "        mask_per_class[class_mask] = color\n",
    "        masks_per_class.append(mask_per_class)\n",
    "\n",
    "    return colored_mask, masks_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = f'{TEST_FOLDER}/results.csv'\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=headers)\n",
    "    writer.writeheader()  # Write the header once\n",
    "    \n",
    "    for i in range(len(test_dataset)):# [15, 34, 55, 87, 64, 77, 95]:#range(5):\n",
    "        # Randomly select an image from the test dataset\n",
    "        # n = np.random.choice(len(test_dataset))\n",
    "        n=i\n",
    "        image_vis = test_dataset[n][0].astype('uint8')  # Original image for visualization\n",
    "        image, gt_mask = test_dataset[n]  # Image and ground truth\n",
    "        \n",
    "        \n",
    "        if not check_pad(image):\n",
    "            image = pad_to_multiple(image)\n",
    "            image_vis = pad_to_multiple(image_vis)\n",
    "            gt_mask = pad_to_multiple(gt_mask)\n",
    "\n",
    "        gt_mask = gt_mask.squeeze()  # Squeeze the ground truth mask\n",
    "\n",
    "        # Transpose image to match model input shape (C, H, W)\n",
    "        image = np.transpose(image, (2, 0, 1))  # Convert (H, W, C) -> (C, H, W)\n",
    "        \n",
    "        # Convert to tensor and move to the appropriate device\n",
    "        x_tensor = torch.from_numpy(image).float().to(DEVICE).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Perform prediction\n",
    "        with torch.no_grad():\n",
    "            pr_mask = best_model(x_tensor)  # Predict mask\n",
    "            # pr_mask = (pr_mask.squeeze().cpu().numpy().round())  # Convert to numpy array and round values\n",
    "            pr_mask = torch.argmax(pr_mask, dim=1).squeeze(0).cpu().numpy()\n",
    "                \n",
    "        colored_mask, colored_mask_per_class = create_color_mask(pr_mask, class_colors)\n",
    "        print(n)\n",
    "        # Visualize the input image and predicted mask\n",
    "        visualize(\n",
    "            image=image_vis,\n",
    "            mask=colored_mask,\n",
    "            alpha=0.5,\n",
    "            save=f\"{TEST_FOLDER}/Predicted segmentation image {n}\"\n",
    "        )\n",
    "        visualize(\n",
    "            image=image_vis,\n",
    "            mask=gt_mask,\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "        for idx in range(len(CLASSES)):\n",
    "            class_masks = test_dataset.get_mask_by_class(n, idx)\n",
    "            \n",
    "            # plt.subplot(1, 2, 1)\n",
    "            # plt.imshow(colored_mask_per_class[idx])  # Show the color-coded mask\n",
    "            # plt.title(f'Generated class mask: {idx_to_class[idx]}')\n",
    "            # plt.axis('off')\n",
    "\n",
    "            # plt.subplot(1, 2, 2)\n",
    "            # plt.imshow(class_masks)  # Show the color-coded mask\n",
    "            # plt.title(f'Original class mask: {idx_to_class[idx]}')\n",
    "            \n",
    "            # plt.axis('off')\n",
    "            # plt.savefig(f\"{RESULTS_FOLDER}/masks/{n}class{idx}.png\")\n",
    "\n",
    "            # plt.show()\n",
    "            \n",
    "            # Initialize a dictionary to hold row data for the CSV\n",
    "        row = {'Image': n}\n",
    "\n",
    "        for class_id in range(len(CLASSES)):\n",
    "            class_masks = test_dataset.get_mask_by_class(n, idx_to_class[class_id])\n",
    "            # Create binary masks for ground truth and prediction\n",
    "            pred_mask = colored_mask_per_class[class_id]\n",
    "            true_mask = class_masks\n",
    "            min_height = min(pred_mask.shape[0], true_mask.shape[0])\n",
    "            min_width = min(pred_mask.shape[1], true_mask.shape[1])\n",
    "\n",
    "            # Crop both masks to the smallest shape\n",
    "            pred_mask = pred_mask[:min_height, :min_width]\n",
    "            true_mask = true_mask[:min_height, :min_width]\n",
    "            \n",
    "            pred_mask_binary = np.any(pred_mask != (200, 200, 200), axis=-1).astype(np.uint8)\n",
    "            true_mask_binary = np.all(true_mask == (255, 255, 255), axis=-1).astype(np.uint8)\n",
    "            \n",
    "            # Calculate intersection and union\n",
    "            intersection = np.sum(np.logical_and(pred_mask_binary, true_mask_binary))\n",
    "            union = np.sum(np.logical_or(pred_mask_binary, true_mask_binary))\n",
    "\n",
    "            # Calculate the pixel counts for each mask\n",
    "            predicted_pixels = np.sum(pred_mask_binary)\n",
    "            true_pixels = np.sum(true_mask_binary)\n",
    "\n",
    "            # Populate the CSV row\n",
    "            row[f'Pixel predicted {class_id}'] = predicted_pixels\n",
    "            row[f'Pixel true {class_id}'] = true_pixels\n",
    "            row[f'Pixel intersetion {class_id}'] = intersection\n",
    "            row[f'Pixel union {class_id}'] = union\n",
    "\n",
    "        # Write the row directly to the CSV file\n",
    "        writer.writerow(row)\n",
    "        \n",
    "        plt.imshow(colored_mask)  # Show the color-coded mask\n",
    "        plt.title('Color-coded Mask')\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"{RESULTS_FOLDER}/masks/{n}full_mask.png\")\n",
    "        # plt.show()\n",
    "        \n",
    "\n",
    "    print(f\"Results saved to {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas matplotlib seaborn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data from the CSV\n",
    "csv_file = f'{TEST_FOLDER}/results.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "# Assuming df is your dataframe\n",
    "# Extracting predicted and true pixel values for plot generation\n",
    "pixel_columns_predicted = [f'Pixel predicted {i}' for i in range(8)]\n",
    "pixel_columns_true = [f'Pixel true {i}' for i in range(8)]\n",
    "pixel_columns_predicted_renamed = [f'Class {idx_to_class[i]}' for i in range(8)]\n",
    "\n",
    "# 1. Heatmap: Predicted vs True Labels (for the first 8 pixel categories)\n",
    "# Create heatmap for the first image in the dataset\n",
    "heatmap_data = df.iloc[0][pixel_columns_predicted].values.reshape(1, -1)\n",
    "true_labels_data = df.iloc[0][pixel_columns_true].values.reshape(1, -1)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "sns.heatmap([heatmap_data[0], true_labels_data[0]], annot=True, cmap=\"Blues\", xticklabels=pixel_columns_predicted_renamed, yticklabels=['Predicted', 'True'])\n",
    "plt.title(f\"Image 0: Pixel Predictions vs True Labels\")\n",
    "plt.xlabel(\"Pixel Categories\")\n",
    "plt.ylabel(\"Labels\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Precision-Recall for Pixel-wise Classification (Pixel intersection)\n",
    "# Calculate Precision-Recall curve for 'intersection' pixels\n",
    "pixel_columns_intersection = [f'Pixel intersetion {i}' for i in range(8)]\n",
    "true_intersection = df[pixel_columns_true].values.ravel()\n",
    "predicted_intersection = df[pixel_columns_intersection].values.ravel()\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize dictionaries to store precision and recall for each class\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "\n",
    "# Loop over each class (0 to 7)\n",
    "for i in range(8):\n",
    "    # Convert true and predicted values for current class (One-vs-Rest)\n",
    "    true_values = (df[f'Pixel true {i}'].values > 0).astype(int)  # 1 if the class is true, otherwise 0\n",
    "    predicted_values = (df[f'Pixel predicted {i}'].values > 0).astype(int)  # 1 if predicted, otherwise 0\n",
    "    \n",
    "    # Compute the precision and recall for the current class\n",
    "    precision, recall, _ = precision_recall_curve(true_values, predicted_values)\n",
    "    \n",
    "    # Store results in the dictionary\n",
    "    precision_dict[i] = precision\n",
    "    recall_dict[i] = recall\n",
    "\n",
    "# Plot Precision-Recall curves for each class\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(8):\n",
    "    plt.plot(recall_dict[i], precision_dict[i], label=f'Pixel Class {i}')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curves for Each Pixel Class (One-vs-Rest)')\n",
    "plt.legend(title='Pixel Classes')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Sum up all predicted and true values across the dataset\n",
    "heatmap_data_sum = df[pixel_columns_predicted].sum().values.reshape(1, -1)\n",
    "true_labels_data_sum = df[pixel_columns_true].sum().values.reshape(1, -1)\n",
    "\n",
    "# Normalization of values\n",
    "max_value = max([heatmap_data_sum.max(), true_labels_data_sum.max()])\n",
    "heatmap_data_sum = heatmap_data_sum / max_value\n",
    "true_labels_data_sum = true_labels_data_sum / max_value\n",
    "\n",
    "# Create a combined heatmap\n",
    "plt.figure(figsize=(10, 3))\n",
    "sns.heatmap(\n",
    "    [heatmap_data_sum[0], true_labels_data_sum[0]],\n",
    "    annot=True,\n",
    "    fmt=\".5f\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=pixel_columns_predicted_renamed,\n",
    "    yticklabels=['Predicted', 'True']\n",
    ")\n",
    "plt.title(\"Summed Pixel Predictions vs True Labels (Normalized)\")\n",
    "plt.xlabel(\"Pixel Categories\")\n",
    "plt.ylabel(\"Labels\")\n",
    "plt.savefig(f\"{TEST_FOLDER}/heat_map.png\")\n",
    "plt.show()\n",
    "\n",
    "print(heatmap_data_sum)\n",
    "print(true_labels_data_sum)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Models and corresponding file paths\n",
    "models = [\"DeepLabV3\", \"DeepLabV3Plus\", \"FPN\", \"Linknet\", \"MAnet\", \"Unet\", \"UnetPlusPlus\"]\n",
    "csv_files = [f\"results/{val}/1-epochs10/training_results_lr=1e-4.csv\" for val in models]\n",
    "\n",
    "# Initialize a dictionary to store the data\n",
    "data = {}\n",
    "\n",
    "# Load the CSV files into a dictionary\n",
    "for model, file in zip(models, csv_files):\n",
    "    data[model] = pd.read_csv(file)\n",
    "\n",
    "# Define the metrics for comparison\n",
    "metrics = [\"Train Loss\", \"Train IoU\", \"Validation Loss\", \"Validation IoU\"]\n",
    "\n",
    "# Plot each metric\n",
    "for metric in metrics:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model in models:\n",
    "        plt.plot(data[model][metric], label=model)\n",
    "    plt.title(f\"Comparison of {metric} Across Models\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from matplotlib.colors import Normalize, LinearSegmentedColormap\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "test_csv_files = [f\"results/{val}/1-epochs10/test_results_lr=1e-4.csv\" for val in models]\n",
    "\n",
    "test_loss = []\n",
    "test_iou = []\n",
    "\n",
    "# Load the test metrics\n",
    "for file in test_csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    test_loss.append(df[\"Test Loss\"].values[0])\n",
    "    test_iou.append(df[\"Test IoU\"].values[0])\n",
    "\n",
    "# Normalize the values for coloring\n",
    "loss_norm = Normalize(vmin=min(test_loss), vmax=max(test_loss))\n",
    "iou_norm = Normalize(vmin=min(test_iou), vmax=max(test_iou))\n",
    "\n",
    "# Get the colormap\n",
    "cmap = get_cmap(\"RdYlGn\")\n",
    "greens = LinearSegmentedColormap.from_list(\"greens\", [\"#e6ffe6\", \"#006600\"])  # Light green to dark green\n",
    "reds = LinearSegmentedColormap.from_list(\"reds\", [\"#ffe6e6\", \"#990000\"])     # Light red to dark red\n",
    "\n",
    "# Create bar plots for Test Loss and Test IoU\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Test Loss Bar Plot\n",
    "loss_colors = [reds(1 - loss_norm(val)) for val in test_loss]  # Invert the colormap\n",
    "axes[0].bar(models, test_loss, color=loss_colors)\n",
    "axes[0].set_title(\"Test Loss Across Models\")\n",
    "axes[0].set_ylabel(\"Test Loss\")\n",
    "axes[0].set_xticklabels(models, rotation=45)\n",
    "axes[0].set_ylim(0,1)\n",
    "\n",
    "# Test IoU Bar Plot\n",
    "iou_colors = [greens(iou_norm(val)) for val in test_iou]\n",
    "axes[1].bar(models, test_iou, color=iou_colors)\n",
    "axes[1].set_title(\"Test IoU Across Models\")\n",
    "axes[1].set_ylabel(\"Test IoU\")\n",
    "axes[1].set_xticklabels(models, rotation=45)\n",
    "axes[1].set_ylim(0,1)\n",
    "\n",
    "# Add colorbars for context\n",
    "fig.colorbar(plt.cm.ScalarMappable(norm=loss_norm, cmap=reds.reversed()), ax=axes[0], orientation='vertical', label='Loss Intensity')\n",
    "fig.colorbar(plt.cm.ScalarMappable(norm=iou_norm, cmap=greens), ax=axes[1], orientation='vertical', label='IoU Intensity')\n",
    "# Adjust layout and show plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(test_iou)\n",
    "print(test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
